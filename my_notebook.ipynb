{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24.02.24\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"set/train.csv\", delimiter=\",\")\n",
    "test = pd.read_csv(r\"set/test.csv\", delimiter=\",\")\n",
    "sample_sub = pd.read_csv(\"set/sample_solution.csv\", index_col=\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.iloc[:, 2:]).reshape(-1, 28, 28, 1).astype(np.float32) / 255.0\n",
    "X_test = np.array(test.iloc[:, 1:]).reshape(-1, 28, 28, 1).astype(np.float32) / 255.0\n",
    "y_train = train['Categoria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y_train)\n",
    "y_col = y.columns  \n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# # First layer, which has a 2D Convolutional layer with kernel size as 3x3 and Max pooling operation\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=(28,28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# Second layer, which has a 2D Convolutional layer with kernel size as 3x3 & ReLU activation and Max pooling operation\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# Fully connected layer with ReLU activation function \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "# Output layer with softmax activation function\n",
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# visualkeras.layered_view(model)\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = model.fit(X_train, y, epochs=75, batch_size=128, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save first prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "pred_df = pd.DataFrame(prediction,columns=y_col,index=sample_sub.index)\n",
    "prediction_col = pred_df.idxmax(axis=1)\n",
    "sample_sub.Categoria = prediction_col\n",
    "\n",
    "sample_sub.to_csv(\"submission_1.csv\",index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tuning the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# First Convolutional layer:\n",
    "# - He normal initialization: An initialization technique to set initial weights.\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer='he_normal', input_shape=(28,28, 1)))\n",
    "\n",
    "# - Reduces the spatial dimensions of the input volume.\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second Convolutional layer:\n",
    "# - 64 filters: Captures 64 different features in the input volume.\n",
    "# - Kernel size 3x3: Each filter scans through 3x3 patches of the input volume.\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "\n",
    "# - Pool size 2x2: Reduces the dimensionality by taking the maximum value within each 2x2 patch.\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# - Dropout rate 0.3: 30% of the input units are randomly dropped during training.\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "# - Normalizes the activations of the previous layer at each batch.\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# - 128 filters: Captures 128 different features in the input volume.\n",
    "# - Kernel size 3x3: Each filter scans through 3x3 patches of the input volume.\n",
    "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "\n",
    "# Max pooling layer:\n",
    "# - Reduces the spatial dimensions of the input volume.\n",
    "# - Pool size 2x2: Reduces the dimensionality by taking the maximum value within each 2x2 patch.\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# - Helps prevent overfitting by randomly setting a fraction of input units to zero.\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "\n",
    "# - Flattens the input volume into a 1D array to be fed into a fully connected layer.\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# - Normalizes the activations of the previous layer at each batch.\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Fully connected Dense layer:\n",
    "# - 512 units: Each unit represents a weight that will be learned during training.\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Dropout layer:\n",
    "# - Helps prevent overfitting by randomly setting a fraction of input units to zero.\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Output Dense layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_2 = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=optimizer_2, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = model.fit(X_train, y, epochs=75, batch_size=128, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save second prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "pred_df = pd.DataFrame(prediction,columns=y_col,index=sample_sub.index)\n",
    "prediction_col = pred_df.idxmax(axis=1)\n",
    "sample_sub.Categoria = prediction_col\n",
    "\n",
    "sample_sub.to_csv(\"submission_2.csv\",index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
